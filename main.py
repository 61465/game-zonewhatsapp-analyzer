import streamlit as st
import pandas as pd
import re
import plotly.express as px
from collections import Counter
import time

# --- Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø© ÙˆØ§Ù„Ù‡ÙˆÙŠØ© Ø§Ù„Ø¨ØµØ±ÙŠØ© ---
st.set_page_config(page_title="Game Zone | WhatsApp Analyzer", layout="wide")

# ØªØµÙ…ÙŠÙ… CSS Ù…Ø®ØµØµ Ù„Ù„Ø«ÙŠÙ… Ø§Ù„Ø£Ø³ÙˆØ¯ ÙˆØ§Ù„Ø°Ù‡Ø¨ÙŠ
st.markdown("""
    <style>
    .main { background-color: #0a0a0a; color: #e0e0e0; }
    .stMetric { background-color: #1a1a1a; border-right: 5px solid #D4AF37; padding: 15px; border-radius: 5px; }
    div[data-testid="stMetricValue"] { color: #D4AF37; }
    .css-10trblm { color: #D4AF37; } /* Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ† */
    h1, h2, h3 { color: #D4AF37 !important; border-bottom: 1px solid #333; }
    .stButton>button { background-color: #D4AF37; color: black; border-radius: 20px; width: 100%; font-weight: bold; }
    </style>
    """, unsafe_allow_html=True)

# --- ÙˆØ¸Ø§Ø¦Ù Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ---
class WhatsAppAnalyzer:
    def __init__(self, file_lines):
        self.lines = file_lines
        self.df = None

    def parse_data(self):
        """ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Øµ Ø§Ù„Ø®Ø§Ù… Ø¥Ù„Ù‰ DataFrame Ù…Ù†Ø¸Ù…"""
        # Ù†Ù…Ø· Regex Ø°ÙƒÙŠ ÙŠØ¯Ø¹Ù… Ù…Ø¹Ø¸Ù… ØªÙ†Ø³ÙŠÙ‚Ø§Øª Ø£Ù†Ø¯Ø±ÙˆÙŠØ¯ ÙˆØ¢ÙŠÙÙˆÙ†
        pattern = r'(\d{1,2}/\d{1,2}/\d{2,4}),\s(\d{1,2}:\d{2}(?::\d{2})?\s?[APM]*)\s-\s([^:]+):\s(.+)'
        
        extracted_data = []
        for line in self.lines:
            match = re.match(pattern, line)
            if match:
                extracted_data.append(match.groups())
        
        self.df = pd.DataFrame(extracted_data, columns=['Date', 'Time', 'User', 'Message'])
        return self.df

    def get_top_words(self, n=10):
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ù…Ø¹ ØªØµÙÙŠØ© Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø´Ø§Ø¦Ø¹Ø©"""
        # Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„ØªÙŠ ÙŠØ¬Ø¨ ØªØ¬Ø§Ù‡Ù„Ù‡Ø§ (Stopwords)
        stop_words = set(['Ù…Ù†', 'Ø¹Ù„Ù‰', 'ÙÙŠ', 'Ø¥Ù„Ù‰', 'Ù‡Ø°Ø§', 'ÙƒØ§Ù†', 'Ø£Ùˆ', 'Ù…Ø§', 'Ù„Ø§', 'Ù‡Ù„', 'ÙŠØ§', 'Ø¥Ù„ÙŠ', 'ØªÙ…', 'Ø¹Ù†', 'Ù…Ø¹', 'Ù‡Ø°Ù‡', 'Ø§Ù„Ù„ÙŠ', 'Ø§Ù†', 'Ø§Ù„Ù„Ù‰'])
        
        all_text = " ".join(self.df['Message']).lower()
        # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Øµ Ù…Ù† Ø§Ù„Ø±Ù…ÙˆØ²
        words = re.findall(r'\b\w{3,}\b', all_text) # Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„ØªÙŠ Ø·ÙˆÙ„Ù‡Ø§ Ø£ÙƒØ«Ø± Ù…Ù† 2 Ø­Ø±Ù ÙÙ‚Ø·
        filtered_words = [word for word in words if word not in stop_words]
        
        return Counter(filtered_words).most_common(n)

# --- ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ---
st.title("ğŸ® GAME ZONE - WHATSAPP ANALYZER")
st.write("Ø­Ù„Ù„ Ù…Ø­Ø§Ø¯Ø«Ø§ØªÙƒ Ø¨Ø£Ø³Ù„ÙˆØ¨ Ø§Ù„Ù…Ø­ØªØ±ÙÙŠÙ†")

uploaded_file = st.file_uploader("Ù‚Ù… Ø¨Ø±ÙØ¹ Ù…Ù„Ù Ø§Ù„Ø¯Ø±Ø¯Ø´Ø© (txt)", type="txt")

if uploaded_file:
    # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    bytes_data = uploaded_file.getvalue().decode("utf-8").splitlines()
    analyzer = WhatsAppAnalyzer(bytes_data)
    
    # ØªØ£Ø«ÙŠØ± Ø§Ù„ØªØ­Ù…ÙŠÙ„ (Ø§Ù„Ø³Ø§Ø¹Ø© Ø§Ù„Ø±Ù…Ù„ÙŠØ©)
    with st.status("Ø¬Ø§Ø±ÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØªØ­Ù„ÙŠÙ„Ù‡Ø§...", expanded=True) as status:
        st.write("ğŸ” ÙØ­Øµ Ø¨Ù†ÙŠØ© Ø§Ù„Ù…Ù„Ù...")
        df = analyzer.parse_data()
        time.sleep(1)
        st.write("ğŸ“Š Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø´Ø®ØµÙŠØ©...")
        time.sleep(1)
        st.write("ğŸ§  ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø£ÙƒØ«Ø± ØªÙƒØ±Ø§Ø±Ø§Ù‹...")
        status.update(label="Ø§ÙƒØªÙ…Ù„ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø¨Ù†Ø¬Ø§Ø­!", state="complete", expanded=False)

    if not df.empty:
        # Ø§Ù„ØµÙ Ø§Ù„Ø£ÙˆÙ„: Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø³Ø±ÙŠØ¹Ø©
        col1, col2, col3 = st.columns(3)
        col1.metric("Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„", f"{len(df):,}")
        col2.metric("Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø´Ø§Ø±ÙƒÙŠÙ†", df['User'].nunique())
        col3.metric("Ù…ØªÙˆØ³Ø· Ø§Ù„ÙƒÙ„Ù…Ø§Øª/Ø±Ø³Ø§Ù„Ø©", round(df['Message'].str.split().str.len().mean(), 1))

        st.markdown("---")

        # Ø§Ù„ØµÙ Ø§Ù„Ø«Ø§Ù†ÙŠ: Ø§Ù„Ø±Ø³ÙˆÙ… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠØ©
        left_column, right_column = st.columns(2)

        with left_column:
            st.subheader("ğŸ‘¥ ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„ Ø­Ø³Ø¨ Ø§Ù„Ø£Ø´Ø®Ø§Øµ")
            user_counts = df['User'].value_counts().reset_index()
            user_counts.columns = ['Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…', 'Ø¹Ø¯Ø¯ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„']
            fig_users = px.pie(user_counts, values='Ø¹Ø¯Ø¯ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„', names='Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…', 
                             color_discrete_sequence=px.colors.sequential.Goldenrod)
            fig_users.update_layout(paper_bgcolor='rgba(0,0,0,0)', plot_bgcolor='rgba(0,0,0,0)', font_color="white")
            st.plotly_chart(fig_users, use_container_width=True)

        with right_column:
            st.subheader("ğŸ† Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø¹Ø´Ø± Ø§Ù„Ø£ÙƒØ«Ø± ØªÙƒØ±Ø§Ø±Ø§Ù‹")
            top_words = analyzer.get_top_words(10)
            words_df = pd.DataFrame(top_words, columns=['Ø§Ù„ÙƒÙ„Ù…Ø©', 'Ø§Ù„ØªÙƒØ±Ø§Ø±'])
            fig_words = px.bar(words_df, x='Ø§Ù„ØªÙƒØ±Ø§Ø±', y='Ø§Ù„ÙƒÙ„Ù…Ø©', orientation='h',
                             color_discrete_sequence=['#D4AF37'])
            fig_words.update_layout(paper_bgcolor='rgba(0,0,0,0)', plot_bgcolor='rgba(0,0,0,0)', font_color="white")
            st.plotly_chart(fig_words, use_container_width=True)

        # Ø¹Ø±Ø¶ Ø¹ÙŠÙ†Ø© Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ù†Ø¸Ù…Ø©
        with st.expander("ğŸ“ Ø¹Ø±Ø¶ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø­Ù„Ù„Ø© Ø¨Ø§Ù„ÙƒØ§Ù…Ù„"):
            st.dataframe(df, use_container_width=True)
            
    else:
        st.error("âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª ØµØ§Ù„Ø­Ø©. ØªØ£ÙƒØ¯ Ù…Ù† ØªØµØ¯ÙŠØ± Ø§Ù„Ø¯Ø±Ø¯Ø´Ø© Ø¨Ø´ÙƒÙ„ ØµØ­ÙŠØ­ Ù…Ù† ÙˆØ§ØªØ³Ø§Ø¨.")

else:
    st.info("ğŸ’¡ Ù†ØµÙŠØ­Ø©: Ø§Ø°Ù‡Ø¨ Ø¥Ù„Ù‰ ÙˆØ§ØªØ³Ø§Ø¨ -> Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª -> Ø§Ù„Ø¯Ø±Ø¯Ø´Ø§Øª -> Ø³Ø¬Ù„ Ø§Ù„Ø¯Ø±Ø¯Ø´Ø§Øª -> Ù†Ù‚Ù„ Ø§Ù„Ø¯Ø±Ø¯Ø´Ø© (Ø¨Ø¯ÙˆÙ† ÙˆØ³Ø§Ø¦Ø·) Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù„Ù.")